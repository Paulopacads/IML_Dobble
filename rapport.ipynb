{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2c0bfe",
   "metadata": {},
   "source": [
    "# Projet IML \n",
    "Membres : Paul Galand, Alexandre James, Temano Frogier, Antoine Aubin\n",
    "\n",
    "## Objectif\n",
    "Notre objectif est de créer une IA capable de reconnaitre les symbôles du jeu Dobble. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209c6aa",
   "metadata": {},
   "source": [
    "## Classificateur d'Images\n",
    "### Entraîner sur des images brutes\n",
    "Avant de nous baser sur des caractéristiques extraites des images, nous voulons tester la performance d'un classificateur entrainé sur des images brutes.\n",
    "- Les images sont au format RGB\n",
    "- Il s'agit de n'importe quel symbole du jeu Dobble, dans n'importe quelle rotation\n",
    "- Nous nous sommes permis de redimensionner les images pour faciliter l'apprentissage\n",
    "\n",
    "### Procédé\n",
    "#### Augmenter le nombre d'images\n",
    "Le dataset donné ne contenant pas suffisament d'images (5 de chaque symboles, dont 2 que nous réservons pour la prédiction), nous augmentons le nombre d'images en entraînement de quelques milliers en effectuant une rotation aléatoire d'une image existante.\n",
    "\n",
    "Comme nous nous soucions de la répartition pour entrainer uniformément les données, cette fonction possède une matrice de visite empêchant un symbole d'etre trop ou trop peu dupliqué. Cette matrice est réinitialisée une fois toutes les images originales rencontrés aléatoirement.\n",
    "\n",
    "Voici la répartition des images par type de symbole:\n",
    "![](https://i.imgur.com/RTCikGD.png)\n",
    "\n",
    "#### Redimensionner les images\n",
    "Toutes nos images n'ont pas les memes dimensions, ce qui est problématique pour le classificateur qui a un nombre statique de neurones en entrée.\n",
    "\n",
    "Ainsi, nous avons construit une fonction permettant de redimensionner nos images dans un carré de 60x60 pixels, tout en gardant le meme ratio d'aspect.\n",
    "\n",
    "### Résultats obtenus\n",
    "#### Précisions\n",
    "\n",
    "Classifier | SVC | LinearSVC\n",
    ":---: | :---: | :---:\n",
    "Temps d'entraînement (m) | 16.27 | 4.01\n",
    "Précision de la prédiction | **0.842** | 0.798\n",
    "\n",
    "Les résultats obtenus sont supérieurs à nos attentes étant donné qu'aucun traitement préalable n'est fait sur les images en entrée.\n",
    "\n",
    "Cependant la précision reste insuffisante, c'est pourquoi nous allons désormais utiliser des classificateurs se basants sur des caractéristiques extraites depuis les images.\n",
    "\n",
    "#### Cas d'erreurs\n",
    "![](https://i.imgur.com/Lk8lO7p.png)\n",
    "![](https://i.imgur.com/qIMz0b0.png)\n",
    "![](https://i.imgur.com/oZroN2P.png)\n",
    "![](https://i.imgur.com/jdjD8qw.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84dda0",
   "metadata": {},
   "source": [
    "## Histogramme couleur\n",
    "### Diminution du nombre de couleur\n",
    "Notre objectif est de diminuer le nombre de couleur présent sur nos images pour pouvoir ensuite plus facilement les comparer. \n",
    "\n",
    "Pour avoir en une image toutes les couleurs présentes dans le jeu Dobble nous concatenons tous les types de symbole du jeu dans un \"poster\" à partir duquel nous trouvons les couleurs les plus représentatives grâce à Kmeans. \n",
    "\n",
    "Nous entrainons un classifier avec les histogrammes obtenus à partir de nos images d'entrainement et nous le testons avec les histogrammes de nos images de tests. \n",
    "\n",
    "Le set de test contient 2 images de chaque classe. \n",
    "Le set d'entrainement contient 3 images de chaque classe. \n",
    "\n",
    "### Résultats obtenus\n",
    "Nombre de couleurs | 5 | 10 | 15 \n",
    ":---: | :---: | :---: | :---: \n",
    "Images recolorisés et leurs histogrammes | ![](https://i.imgur.com/cUQlnDG.png) | ![](https://i.imgur.com/8E4PATX.png) | ![](https://i.imgur.com/C8ilav4.png) |\n",
    "\n",
    "**Précision sans classifier**\n",
    "Nous prenons une image de chaque symbole et réduisons ses couleurs pour déduire un histogramme des couleurs qui y sont présentes.\n",
    "\n",
    "Lorsque nous prenons une image inconnu pour trouver son label il nous suffit de diminuer ses couleurs, faire son histogramme et le comparer à ceux que nous avons calculer précédemment pour lesquels nous connaissons le label. Nous déduisons le label de l'image inconnu en prenant celui de l'histogramme dont elle est le plus proche. \n",
    "\n",
    "Nombre de couleurs | 5 | 8 | 9 | **10** | 11 | 12 | 15\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---: | :---:\n",
    "Précision | 0.930 | 0.947 | 0.938 | **0.965** | 0.965 | 0.947 | 0.964\n",
    "\n",
    "La différence entre les résultats est minime. Nous pouvons voir que le maximum de précision est atteint avec 10 et 11 couleurs et que même en augmentant le nombre de couleur le résultat reste très proche. \n",
    "\n",
    "Pour la suite nous utiliserons uniquement des réductions en 10 couleurs. \n",
    "\n",
    "**Précision avec les classifiers**\n",
    "\n",
    "Classifier | SVC | LinearSVC | KN (3 neighbors) | KN (1 neighbor) | RandomForest (100 estimators) | Dummy\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---: \n",
    "Précision | 0.947 | 0.518 | 0.904 | **0.974** | 0.974 | 0.02\n",
    "\n",
    "L'usage de classifier ne nous permet pas d'améliorer de façon significative notre précision. Dans le cas de la random forest nos résultats sont entre 0.92 et 0.974 selon le nombre d'estimateur. Nous pouvons conclure que dans ce cas des histogrammes couleurs utiliser un classifier améliore peu les résultats. \n",
    "\n",
    "\n",
    "#### Cas d'erreurs \n",
    " ![](https://i.imgur.com/AgRgcpF.png) | ![](https://i.imgur.com/vLkxEpO.png)\n",
    " :---: | :---:\n",
    "\n",
    "Les erreurs rencontrés sont dû à des couleurs identiques entre les symbôles. En prenant en compte la forme nous pourrions ne plus avoir ces erreurs. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d900ffb1",
   "metadata": {},
   "source": [
    "## Descripteur de forme\n",
    "Identifier le descripteur de forme le plus efficace / utile dans notre cas\n",
    "\n",
    "### Topological and geometrical features\n",
    "Mettre des métriques des résultats en utilisant uniquement la forme pour trouver l'objet.\n",
    "\n",
    "L'objectif ici est de pouvoir faire de la reconnaissance de forme en s'intéressant aux features topologiques et géométriques.\n",
    "\n",
    "Nous avons pu extraire les features suivantes:\n",
    "\n",
    "- Nombre de trous\n",
    "- Nombre de composants\n",
    "- Nombre d’Euler\n",
    "- Superficie\n",
    "- Nombre de face du contour convexe\n",
    "- Skeleton\n",
    "\n",
    "Quelques exemples de skeletons:\n",
    "![](https://i.imgur.com/sOHxVKw.png)\n",
    "\n",
    "\n",
    "Puis, nous avons ramené les toutes les features à un float entre 0 et 1 (-1 et 1 pour le nombre d'euler) en les divisant par la valeur max de leur feature respective. Cela afin d'éviter d'avoir des écarts trop grands pour deux mêmes images.\n",
    "\n",
    "De plus, nous avons effectué un gaussian blur sur les skeletons afin d'élargir les lignes du squelette et ainsi éviter les décalages de pixels.\n",
    "\n",
    "Enfin nous avons combiné toutes ces features en early fusion et testé avec différents classifieurs.\n",
    "\n",
    "**Précision avec les classifiers**\n",
    "\n",
    "Classifier | SVC | LinearSVC | KN (3 neighbors) | KN (1 neighbor) | RandomForest (100 estimators) | Dummy\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---: \n",
    "Précision | 0.789 | 0.280 | 0.649 | 0.807 | **0.912** | 0.02\n",
    "\n",
    "Nous avons également testé le classifieur RandomForest avec toutes les features sauf le skeleton cette fois-ci et nous avions un score de 0.5. On peut donc noter que l'ajout seul du skeleton est un point fort dans la reconnaissance de forme.\n",
    "\n",
    "### Moments géometriques\n",
    "\n",
    "#### Intro\n",
    "\n",
    "Un moment de l'image est une certaine moyenne pondérée particulière des intensités des pixels d'une image, ou une fonction de ces moments, généralement choisie pour avoir une propriété intéressante.\n",
    "\n",
    "#### Raw moments\n",
    "\n",
    "Les raw moments sont définis mathématiquement comme suit:\n",
    "$$\n",
    "M_{pq} = \\int\\int{x^py^qf(x,y)dxdy}\n",
    "$$\n",
    "\n",
    "En adaptant cela en code, pour une image $I$, nous revenons finalement a une somme:\n",
    "$$\n",
    "M_{ij} = \\sum_x\\sum_y{x^iy^jI(x,y)}\n",
    "$$\n",
    "\n",
    "Utilisations pratiques:\n",
    "- Somme des niveau de gris voir aire d'une forme pour les images binaires: $M_{00}$\n",
    "- Centroid d'une forme: $C\\{x, y\\} = \\{\\frac{M_{10}}{M_{00}}, \\frac{M_{01}}{M_{00}}\\}$\n",
    "\n",
    "Puisqu'on veut faire une somme des pixels, on passe en niveau de gris (une seule valeur par pixel).\n",
    "\n",
    "Aussi, puisqu'on ne veut prendre en compte que le symbole dans l'image, il ne faut pas que le fond ait beaucoup de valeur. Or le blanc est la valeur maximale (255). On inverse donc les couleurs.\n",
    "\n",
    "![](https://i.imgur.com/reA83ai.png) | ![](https://i.imgur.com/RIBPJYC.png)\n",
    ":---: | :---:\n",
    "Image originale | Grayscale et inversion des couleurs\n",
    "\n",
    "Le probleme de ces moments:\n",
    "- Tres dependant de la taille de l'image, de la position du symbole, ainsi que de sa rotation.\n",
    "\n",
    "#### Central moments\n",
    "\n",
    "Les central moments sont définis mathématiquement comme suit:\n",
    "$$\n",
    "\\mu_{pq} = \\int\\int{(x - \\frac{M_{10}}{M_{00}})^p(y - \\frac{M_{01}}{M_{00}})^qf(x,y)dxdy}\n",
    "$$\n",
    "\n",
    "En adaptant cela en code, pour une image $I$, nous revenons finalement a une somme:\n",
    "$$\n",
    "\\mu_{ij} = \\sum_x\\sum_y{(x - \\frac{M_{10}}{M_{00}})^i(y - \\frac{M_{01}}{M_{00}})^jI(x,y)}\n",
    "$$\n",
    "\n",
    "Il est interessant de noter l'invariance translationnelle de ces moments. Ils ne changent pas vis a vis de la position du symbole. (Calcul en fonction du **centroid** du symbole)\n",
    "\n",
    "#### Scale-invariants moments\n",
    "\n",
    "Les scale-invariants moments sont définis mathématiquement comme suit:\n",
    "$$\n",
    "\\eta_{ij}=\\frac{\\mu_{ij}}{\\mu_{00}^{(1+\\frac{i+j}{2})}}\n",
    "$$\n",
    "\n",
    "Nous restons sur la meme definition en code, puisque cela est reproductible en Python.\n",
    "\n",
    "Comme son nom l'indique, ces moments sont invariants vis a vis de la taille du symbole dans l'image. Puisqu'ils sont calcules a partir des moments centraux, ils sont egalement invariant vis a vis des translations.\n",
    "\n",
    "#### Hu moments\n",
    "\n",
    "Les Hu moments sont définis mathématiquement comme suit:\n",
    "$$\n",
    "I_1 = \\eta_{20} + \\eta_{02}\\\\\n",
    "I_2 = (\\eta_{20} - \\eta_{02})^2 + 4 \\times \\eta_{11}^2\\\\\n",
    "I_3 = (\\eta_{30} - 3 \\times \\eta_{12})^2 + (3 \\times \\eta_{21} - \\eta_{03})^2\\\\\n",
    "I_4 = (\\eta_{30} + \\eta_{12})^2 + (\\eta_{21} + \\eta_{03})^2\\\\\n",
    "I_5 = (\\eta_{30} - 3 \\times \\eta_{12}) \\times (\\eta_{30} + \\eta_{12}) \\times [(\\eta_{30} + \\eta_{12})^2 - 3 \\times (\\eta_{21} + \\eta_{03})^2] + (3 \\times \\eta_{21} - \\eta_{03}) \\times (\\eta_{21} + \\eta_{03}) \\times [3 \\times (\\eta_{30} + \\eta_{12})^2 - (\\eta_{21} + \\eta_{03})^2]\\\\\n",
    "I_6 = (\\eta_{20} - \\eta_{02}) \\times [(\\eta_{30} + \\eta_{12})^2 - (\\eta_{21} + \\eta_{03})^2] + 4 \\times \\eta_{11} \\times (\\eta_{30} + \\eta_{12}) \\times (\\eta_{21} + \\eta_{03})\\\\\n",
    "I_7 = (3 \\times \\eta_{21} - \\eta_{03}) \\times (\\eta_{30} + \\eta_{12}) \\times [(\\eta_{30} + \\eta_{12})^2 - 3 \\times (\\eta_{21} + \\eta_{03})^2] - (\\eta_{30} - 3 \\times \\eta_{12}) \\times (\\eta_{21} + \\eta_{03}) \\times [3 \\times (\\eta_{30} + \\eta_{12})^2 - (\\eta_{21} + \\eta_{03})^2]\n",
    "$$\n",
    "\n",
    "Ces 7 moments sont invariants vis a vis de la taille, la translation (puisqu'ils s'appuient sur les moments ci-dessus), ainsi que la rotation du symbole.\n",
    "\n",
    "Ainsi, on arrive a avoir des descripteurs tres interessants pour les images donnees afin d'entrainer nos classifiers.\n",
    "\n",
    "Hu Moments de l'image ci-dessus:\n",
    "```python\n",
    "H = [0.00107824903655817520, # I1\n",
    "     2.8838116870670213e-08, # I2\n",
    "     4.8736175827331650e-11, # I3\n",
    "     6.9759253200071600e-12, # I4\n",
    "     1.2859676622039428e-22, # I5\n",
    "     1.1826192247697838e-15, # I6\n",
    "     2.7379338127329156e-24] # I7\n",
    " ```\n",
    "\n",
    "#### Précision avec les classifiers\n",
    "\n",
    "On obtient des resultats tres interessants sur nos classifiers:\n",
    "\n",
    "Classifier |  Dummy | LinearSVC | KNeighbors | SVC | RandomForest |\n",
    ":---: | :---: | :---: | :---: | :---: | :---: |\n",
    "Précision | 0.018 | 0.280 | 0.421 | 0.851 | **0.991** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43921f62",
   "metadata": {},
   "source": [
    "\n",
    "## Fusion de charactéristiques\n",
    "### Early fusion\n",
    "Pour la early fusion nous avons fais le choix d'unir nos charactéristiques de couleurs avec nos moments géométriques (Hu) grace a une concatenation des caracteristiques.\n",
    "\n",
    "Puisque nous avons 10 informations dans nos histogrammes de couleur, et 7 moments geometriques, nous avons juge que l'equilibre entre les deux descripteurs etait suffisant pour ne pas avoir besoin de complexifier la concatenation.\n",
    "\n",
    "Voici les résultats que nous avons obtenus :\n",
    "\n",
    " Classifier | Dummy | KNeighbors | SVC | Linear SVC | RandomForest |\n",
    " :---: | :---: | :---: | :---: | :---: | :---: |\n",
    " Précision | 0.018 | 0.5 | 0.965 | 0.974 | 1 |\n",
    "\n",
    "\n",
    "### Late fusion\n",
    "Pour la fusion tardive des charactèristiques nous avons choisi de combiner notre descripteur de forme avec Hu Moments et nos histogrammes de couleurs. \n",
    "\n",
    "Nous avons choisit un KNeighbors classifier avec 5 voisins pour l'histogramme couleur car ce classifier permet d'avoir un score de detection répartit entre 3 et 5 choix en ayant pendant nos tests toujours la bonne réponse parmis ces choix. L'utilisation d'un KNeighbors avec 1 seul voisin peut fausser nos résultat lors de la fusion car le choix même lorqu'il est faux a un score de 1 lui faisant gagner trop de force par rapport aux scores de notre classifier avec descripteur de forme. \n",
    "\n",
    "Pour le classifier du descripteur de forme nous restons sur le RandomForest avec 4 estimateurs qui nous donne des résultats juste dans 99-100% des cas. \n",
    "\n",
    "**Bilan** : Nous obtenons un score de **100% de précision** avec nos tests. \n",
    "\n",
    "## Travail de chacun \n",
    "Alexandre | Antoine | Paul | Temano\n",
    " :---: | :---: | :---: | :---:\n",
    "Classifier d'images | Histogrammes couleurs | Préparations des datasets (séparation et récupération) | Descripteur de forme - Extraction des features Topologiques et géométriques\n",
    "Augmentation du dataset | Late fusion | Hu moments | Early fusion des features Topologiques et géométriques\n",
    "Vidéo | / | Early and late fusion (color + Hu moments) | /"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
