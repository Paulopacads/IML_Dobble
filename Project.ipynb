{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import shutil as su\n",
    "import random as rd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p tmp_data\n",
    "rm -rf tmp_data/*\n",
    "mkdir -p tmp_data/train_set\n",
    "mkdir -p tmp_data/test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(path, nb_elements=1):\n",
    "    \"\"\"\n",
    "    Separate given data in `path` in two sets with `nb_elements` per class for test\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to directory where dataset files are stored.\n",
    "\n",
    "    nb_elements: integer\n",
    "        Defines the number of test images taken in each class of the dataset\n",
    "    \"\"\"\n",
    "    labels_path = os.path.join(path, \"labels.txt\")\n",
    "    images_path = path\n",
    "    test_path = 'tmp_data/test_set'\n",
    "    train_path = 'tmp_data/train_set'\n",
    "\n",
    "    \n",
    "    labels = np.empty((0, 1))\n",
    "    names = np.empty((0, 1))\n",
    "    with open(labels_path) as f:\n",
    "        for current_label in f:\n",
    "            if current_label == \"\\n\":\n",
    "                continue\n",
    "            label, name = current_label.split(\": \")\n",
    "            labels = np.append(labels, label)\n",
    "            names = np.append(names, name)\n",
    "\n",
    "    for label in labels:\n",
    "        pre_label = 'img_' + label + '_'\n",
    "        curr_test_path = os.path.join(test_path, label)\n",
    "        curr_train_path = os.path.join(train_path, label)\n",
    "        os.makedirs(curr_test_path, exist_ok=True)\n",
    "        os.makedirs(curr_train_path, exist_ok=True)\n",
    "\n",
    "        current_path = os.path.join(images_path, label)\n",
    "        datas = os.listdir(current_path)\n",
    "        rd.shuffle(datas)\n",
    "\n",
    "        count = 0\n",
    "        for data in datas:\n",
    "            data_path = os.path.join(current_path, data)\n",
    "            if count < nb_elements:\n",
    "                su.copyfile(data_path, os.path.join(curr_test_path, pre_label + str(count) + '.png'))\n",
    "            else:\n",
    "                su.copyfile(data_path, os.path.join(curr_train_path, pre_label + str(count - nb_elements) + '.png'))\n",
    "            count += 1\n",
    "\n",
    "    return labels, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref = separate_data('ressources/train', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get separated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(kind='train'):\n",
    "    \"\"\"\n",
    "    Returns `kind` set and their label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kind: str (train or test)\n",
    "        Type of dataset we want to get\n",
    "    \"\"\"\n",
    "    assert kind == 'train' or kind == 'test'\n",
    "    dataset_path = 'tmp_data/train_set' if kind == 'train' else 'tmp_data/test_set'\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    dirs = os.listdir(dataset_path)\n",
    "\n",
    "    for folder in dirs : \n",
    "        curr_path = os.path.join(dataset_path, folder)\n",
    "        datas = os.listdir(curr_path)\n",
    "        for data in datas:\n",
    "            data_path = os.path.join(curr_path, data)\n",
    "            img = cv2.imread(data_path);\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\n",
    "            images.append(img)\n",
    "            labels.append(folder)\n",
    "    \n",
    "    return labels, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_images = get_datasets('train')\n",
    "test_labels, test_images = get_datasets('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_set(labels, images):\n",
    "    \"\"\"\n",
    "    Shuffles equally labels and images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: [str]\n",
    "        Dataset's labels\n",
    "        \n",
    "    images: [image]\n",
    "        Dataset's images\n",
    "    \"\"\"\n",
    "    assert len(labels) == len(images)\n",
    "    shuffle_index = np.arange(len(labels))\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    new_labels = np.array(labels)\n",
    "    new_images = np.array(images, dtype=object)\n",
    "    \n",
    "    for ii in range(shuffle_index.size):\n",
    "        new_labels[ii] = labels[shuffle_index[ii]]\n",
    "        new_images[ii] = images[shuffle_index[ii]]\n",
    "        \n",
    "    return new_labels, new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels, train_images = shuffle_set(train_labels, train_images)\n",
    "test_labels, test_images = shuffle_set(test_labels, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0])\n",
    "print(ref[1][np.where(ref[0] == train_labels[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_labels[0])\n",
    "plt.imshow(test_images[0])\n",
    "print(ref[1][np.where(ref[0] == test_labels[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all indices for a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_labeled(label, labels):\n",
    "    \"\"\"\n",
    "    Returns all indices of element like `label` in `labels`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label: str\n",
    "        Searched label\n",
    "    \n",
    "    labels: [str]\n",
    "        Dataset's labels\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(labels.size):\n",
    "        if labels[i] == label:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "find_all_labeled(train_labels[0], train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "If you executed all of the above, you defined the following variables:\n",
    "\n",
    "```python\n",
    "ref # couple:\n",
    "    ref[0] # labels' identifiers\n",
    "    ref[1] # labels\n",
    "\n",
    "train_labels # train dataset's images' identifiers for labels\n",
    "\n",
    "train_images # train dataset's images\n",
    "\n",
    "test_labels # test dataset's images' identifiers for labels\n",
    "\n",
    "test_images # test dataset's images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color histogram\n",
    "### 1. Color quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_each_image() :\n",
    "    \"\"\"\n",
    "    Return one image of each type with corresponding labels\n",
    "    \"\"\"\n",
    "    PATH_TO_RESOURCES = \"ressources/train\"\n",
    "    images = []\n",
    "    dirs = os.listdir(PATH_TO_RESOURCES)\n",
    "    labels = []\n",
    "    for name_dir in dirs : \n",
    "        if name_dir == \"labels.txt\" :\n",
    "            continue\n",
    "        actual_path = os.path.join(PATH_TO_RESOURCES, name_dir)\n",
    "        img_name = os.listdir(actual_path)[0]\n",
    "        img = cv2.imread(os.path.join(actual_path, img_name));\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\n",
    "        images.append(img)\n",
    "        labels.append(name_dir)\n",
    "    return images, labels\n",
    "\n",
    "each_images, each_labels = get_each_image()\n",
    "plt.imshow(each_images[52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poster(images) : \n",
    "    \"\"\"\n",
    "    Return a poster containing all images and a corresponding mask\n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    images: [image]\n",
    "        Dataset's images\n",
    "    \"\"\"\n",
    "    sizeImg = 250\n",
    "    img0 = cv2.resize(images[0], (sizeImg, sizeImg))\n",
    "    poster = img0\n",
    "    first = True\n",
    "    for img in images : \n",
    "        if first : \n",
    "            first = False\n",
    "            continue\n",
    "        img = cv2.resize(img, (sizeImg, sizeImg))\n",
    "        poster = cv2.hconcat([poster, img])\n",
    "    \n",
    "    # Create a mask for the poster generated \n",
    "    poster_mask = np.zeros(poster.shape[0] * poster.shape[1])\n",
    "    for i in range(poster.shape[0]) : \n",
    "        for j in range(poster.shape[1]) : \n",
    "            poster_mask[i * poster.shape[0] +  j] = np.all(poster[i, j] != 255)\n",
    "    \n",
    "    return poster, poster_mask\n",
    "\n",
    "poster, poster_mask = create_poster(each_images)\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(poster)\n",
    "poster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def train_kmeans(poster, nb_colors) :\n",
    "    \"\"\"\n",
    "    'Train' kmeans using poster's colors \n",
    "    Parameters\n",
    "    ----------\n",
    "    poster: image\n",
    "        \n",
    "    nb_colors: int\n",
    "        Number of clusters for kmeans\n",
    "    \"\"\"\n",
    "    plane_poster = poster.reshape(len(poster) * len(poster[0]), 3)\n",
    "    kmeans = KMeans(n_clusters=nb_colors, random_state=0)\n",
    "    kmeans.fit(plane_poster)\n",
    "    kmeans.cluster_centers_\n",
    "    label_map = kmeans.predict(plane_poster)\n",
    "    return kmeans, label_map\n",
    "\n",
    "kmeans, label_map = train_kmeans(poster, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lut = np.uint8(kmeans.cluster_centers_)\n",
    "plt.bar(np.arange(len(color_lut)), \n",
    "         np.ones(len(color_lut)), \n",
    "         color=color_lut/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Color histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_color(img, kmeans) : \n",
    "    \"\"\"\n",
    "    Reduce the colors in an image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img: image\n",
    "        Reference image\n",
    "    kmeans: Kmeans\n",
    "        kmeans used to determine new colors\n",
    "    \"\"\"\n",
    "    newImg = np.zeros_like((0, 0, 0), shape=img.shape)\n",
    "    prediction = kmeans.predict(img.reshape(len(img) * len(img[0]), 3))\n",
    "    histo = np.zeros(len(kmeans.cluster_centers_))\n",
    "    for i in range(len(img)) : \n",
    "        for j in range(len(img[0])) :\n",
    "            if img[i, j][0] == 255 and img[i, j][1] == 255 and img[i, j][2] == 255: \n",
    "                newImg[i, j] = [255, 255,255]\n",
    "            else :\n",
    "                newImg[i, j] = kmeans.cluster_centers_[prediction[i * len(img[0]) + j]]\n",
    "                histo[prediction[i * len(img[0]) + j]] += 1\n",
    "    return newImg, histo\n",
    "\n",
    "def normalize_histogram(histo) : \n",
    "    \"\"\"\n",
    "    Normalize histogram\n",
    "    \n",
    "    Parameter\n",
    "    ----------\n",
    "    histo: [int]\n",
    "        image histogram\n",
    "    \"\"\"\n",
    "    nbPixels = np.sum(histo)\n",
    "    for i in range(len(histo)) : \n",
    "        if histo[i] != 0 :\n",
    "            histo[i] = histo[i] / nbPixels\n",
    "    return histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce color of all images\n",
    "images_quant = []\n",
    "color_histograms = []\n",
    "for i in range(len(each_images)) : \n",
    "    newImg, histo = reduce_color(each_images[i], kmeans)\n",
    "    images_quant.append(newImg)\n",
    "    # Normalise histogram\n",
    "    histo = normalize_histogram(histo)\n",
    "    color_histograms.append(histo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some color histograms with colors!\n",
    "colors_for_bars = color_lut/255  # matplotlib colors are RGB values scaled to [0,1]\n",
    "for ii in range(5):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(each_images[ii])\n",
    "    plt.axis('off'); plt.title(\"Original\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(images_quant[ii])\n",
    "    plt.axis('off'); plt.title(\"Recolored\")\n",
    "    plt.subplot(1,3,3, aspect=len(color_histograms[0]))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.bar(range(len(color_histograms[ii])), \n",
    "            color_histograms[ii]/color_histograms[ii].max(), \n",
    "            color=colors_for_bars)\n",
    "    plt.xticks([]); plt.title(\"Histogram\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without classifier just using histogram comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "good_result = 0\n",
    "for i in range(len(test_images)) : \n",
    "    test_img = test_images[i]\n",
    "    test_img_recolored, test_histo = reduce_color(test_img, kmeans)\n",
    "    test_histo = normalize_histogram(test_histo)\n",
    "    minimal_distance = sc.spatial.distance.pdist(np.vstack((test_histo, color_histograms[0])))\n",
    "    best_index = 0\n",
    "    \n",
    "    for j in range(1, len(color_histograms)) :\n",
    "        dist = sc.spatial.distance.pdist(np.vstack((test_histo, color_histograms[j])))\n",
    "        if dist < minimal_distance : \n",
    "            minimal_distance = dist \n",
    "            best_index = j\n",
    "    # Check que le result est bon\n",
    "    if test_labels[i] == each_labels[best_index] :\n",
    "        good_result += 1\n",
    "    else :\n",
    "        plt.figure(figsize=(5,1))\n",
    "        plt.subplot(1,3, 1)\n",
    "        plt.imshow(test_img)\n",
    "        plt.axis('off'); plt.title(\"Image tested\")\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(each_images[best_index])\n",
    "        plt.axis('off'); plt.title(\"Image found\")\n",
    "        plt.show()\n",
    "    \n",
    "accuracy = good_result / len(test_images)\n",
    "print(\"Accuracy: \", round(accuracy, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images histograms\n",
    "def get_images_histograms(images) : \n",
    "    histograms = []\n",
    "    for i in range(len(images)) : \n",
    "        actual_img = images[i]\n",
    "        actual_img_recolored, img_histo = reduce_color(actual_img, kmeans)\n",
    "        actual_histo = normalize_histogram(img_histo)\n",
    "        histograms.append(actual_histo)\n",
    "    return histograms\n",
    "\n",
    "train_histograms = get_images_histograms(train_images)\n",
    "test_histograms = get_images_histograms(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.dummy\n",
    "import sklearn.ensemble\n",
    "\n",
    "def classifier_test(clf, clf_name) : \n",
    "    clf.fit(train_histograms, train_labels)\n",
    "    label_pred = clf.predict(test_histograms)\n",
    "\n",
    "    good = 0\n",
    "    for i in range(len(label_pred)) : \n",
    "        if label_pred[i] == test_labels[i] :\n",
    "            good += 1\n",
    "    accuracy = good / len(label_pred)\n",
    "    print(clf_name + '. Accuracy:', round(accuracy, 3))\n",
    "\n",
    "print(\"Test de différents classifiers :\\n\")\n",
    "clf = sk.svm.LinearSVC()\n",
    "classifier_test(clf, \"Linear SVC\")\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "classifier_test(clf, \"KNeighbors (1 neighbor)\")\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "classifier_test(clf, \"KNeighbors (3 neighbors)\")\n",
    "classifier_test(sk.dummy.DummyClassifier(), \"Dummy\")\n",
    "classifier_test(sk.ensemble.RandomForestClassifier(n_estimators=10), \"RandomForest (10 estimators)\")\n",
    "classifier_test(sk.ensemble.RandomForestClassifier(n_estimators=100), \"RandomForest (100 estimators)\")\n",
    "classifier_test(sk.ensemble.RandomForestClassifier(n_estimators=57), \"RandomForest (57 estimators)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(train_histograms, train_labels)\n",
    "probas = clf.predict_proba(test_histograms)\n",
    "\n",
    "print(\"Errors found and corresponding probabilities.\\n\")\n",
    "for i in range(len(probas)) :\n",
    "    label_pred = clf.classes_[np.where(probas[i] == np.amax(probas[i]))]\n",
    "    if label_pred[0] != test_labels[i] :\n",
    "        labels_proba = \"\"\n",
    "        for j in range(len(probas[0])) : \n",
    "            if probas[i][j] > 0 : \n",
    "                label = clf.classes_[j]\n",
    "                labels_proba += label + \"/\" + str(probas[i][j]) + \"; \"\n",
    "        print(\"Label wanted:\", test_labels[i], \". Labels get/proba: \", labels_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape matching\n",
    "### 1. Hu moments\n",
    "#### Image treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return np.dot(img[..., :3], [.299, .587, .114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted(img):\n",
    "    img = img.copy()\n",
    "    for ii in range(len(img)):\n",
    "        for jj in range(len(img[0])):\n",
    "            img[ii][jj] = 255 - img[ii][jj]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inverted(grayscale(test_images[11])), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_moment(i, j, img):\n",
    "    moment = 0\n",
    "    for y in range(len(img)):\n",
    "        for x in range(len(img[0])):\n",
    "            moment += x ** i * y ** j * img[y][x]\n",
    "    return moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_moment(i, j, img):\n",
    "    avg_moment = raw_moment(0, 0, img)\n",
    "    x_centroid = raw_moment(1, 0, img) / avg_moment\n",
    "    y_centroid = raw_moment(0, 1, img) / avg_moment\n",
    "    \n",
    "    moment = 0\n",
    "    for y in range(len(img)):\n",
    "        for x in range(len(img[0])):\n",
    "            moment += (x - x_centroid) ** i * (y - y_centroid) ** j * img[y][x]\n",
    "    return moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_moment_opt(centroid, i, j, img):\n",
    "    moment = 0\n",
    "    for y in range(len(img)):\n",
    "        for x in range(len(img[0])):\n",
    "            moment += (x - centroid[0]) ** i * (y - centroid[1]) ** j * img[y][x]\n",
    "    return moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_invariant_moment(i, j, img):\n",
    "    assert i + j >= 2\n",
    "    return central_moment(i, j, img) / central_moment(0, 0, img) ** (1 + (i + j) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_invariant_moment_opt(centroid, c0, i, j, img):\n",
    "    assert i + j >= 2\n",
    "    return central_moment_opt(centroid, i, j, img) / c0 ** (1 + (i + j) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hu Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hu_moments(img):\n",
    "    img_gray = inverted(grayscale(img))\n",
    "    \n",
    "    nu20 = scale_invariant_moment(2, 0, img_gray)\n",
    "    nu11 = scale_invariant_moment(1, 1, img_gray)\n",
    "    nu02 = scale_invariant_moment(0, 2, img_gray)\n",
    "    nu30 = scale_invariant_moment(3, 0, img_gray)\n",
    "    nu21 = scale_invariant_moment(2, 1, img_gray)\n",
    "    nu12 = scale_invariant_moment(1, 2, img_gray)\n",
    "    nu03 = scale_invariant_moment(0, 3, img_gray)\n",
    "    \n",
    "    I0 = (nu20 + nu02)\n",
    "    \n",
    "    I1 = ((nu20 - nu02) ** 2 +\n",
    "          4 * nu11 ** 2)\n",
    "    \n",
    "    I2 = ((nu30 - 3 * nu12) ** 2 +\n",
    "          (3 * nu21 - nu03) ** 2)\n",
    "    \n",
    "    I3 = ((nu30 + nu12) ** 2 +\n",
    "          (nu21 + nu03) ** 2)\n",
    "    \n",
    "    I4 = ((nu30 - 3 * nu12) * (nu30 + nu12) *\n",
    "          ((nu30 + nu12) ** 2 - 3 * (nu21 + nu03) ** 2) +\n",
    "          (3 * nu21 - nu03) * (nu21 + nu03) *\n",
    "          (3 * (nu30 + nu12) ** 2 - (nu21 + nu03) ** 2))\n",
    "    \n",
    "    I5 = ((nu20 - nu02) * ((nu30 + nu12) ** 2 - (nu21 + nu03) ** 2) +\n",
    "          4 * nu11 * (nu30 + nu12) * (nu21 + nu03))\n",
    "    \n",
    "    I6 = ((3 * nu21 - nu03) * (nu30 + nu12) *\n",
    "          ((nu30 + nu12) ** 2 - 3 * (nu21 + nu03) ** 2) -\n",
    "          (nu30 - 3 * nu12) * (nu21 + nu03) *\n",
    "          (3 * (nu30 + nu12) ** 2 - (nu21 + nu03) ** 2))\n",
    "    \n",
    "    return [I0, I1, I2, I3, I4, I5, I6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hu_moments_opt(img):\n",
    "    img_gray = inverted(grayscale(img))\n",
    "    \n",
    "    avg = raw_moment(0, 0, img_gray)\n",
    "    centroid = (raw_moment(1, 0, img_gray) / avg, raw_moment(0, 1, img_gray) / avg)\n",
    "    \n",
    "    c0 = central_moment_opt(centroid, 0, 0, img_gray)\n",
    "    \n",
    "    nu20 = scale_invariant_moment_opt(centroid, c0, 2, 0, img_gray)\n",
    "    nu11 = scale_invariant_moment_opt(centroid, c0, 1, 1, img_gray)\n",
    "    nu02 = scale_invariant_moment_opt(centroid, c0, 0, 2, img_gray)\n",
    "    nu30 = scale_invariant_moment_opt(centroid, c0, 3, 0, img_gray)\n",
    "    nu21 = scale_invariant_moment_opt(centroid, c0, 2, 1, img_gray)\n",
    "    nu12 = scale_invariant_moment_opt(centroid, c0, 1, 2, img_gray)\n",
    "    nu03 = scale_invariant_moment_opt(centroid, c0, 0, 3, img_gray)\n",
    "    \n",
    "    hu = np.zeros(7)\n",
    "    \n",
    "    t0 = nu30 + nu12;\n",
    "    t1 = nu21 + nu03;\n",
    "\n",
    "    q0 = t0 * t0\n",
    "    q1 = t1 * t1;\n",
    "\n",
    "    n4 = 4 * nu11;\n",
    "    s = nu20 + nu02;\n",
    "    d = nu20 - nu02;\n",
    "\n",
    "    hu[0] = s;\n",
    "    hu[1] = d * d + n4 * nu11;\n",
    "    hu[3] = q0 + q1;\n",
    "    hu[5] = d * (q0 - q1) + n4 * t0 * t1;\n",
    "\n",
    "    t0 *= q0 - 3 * q1;\n",
    "    t1 *= 3 * q0 - q1;\n",
    "\n",
    "    q0 = nu30 - 3 * nu12;\n",
    "    q1 = 3 * nu21 - nu03;\n",
    "\n",
    "    hu[2] = q0 * q0 + q1 * q1;\n",
    "    hu[4] = q0 * t0 + q1 * t1;\n",
    "    hu[6] = q1 * t0 - q0 * t1;\n",
    "    \n",
    "    return hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_moments_diff(hu_1, hu_2):\n",
    "    diff = 0\n",
    "    for i in range(7):\n",
    "        diff += (hu_2[i] - hu_1[i]) ** 2\n",
    "        \n",
    "    return math.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments_from(images):\n",
    "    hu_mo = np.zeros((len(images), 7))\n",
    "    for ii in range(len(images)):\n",
    "        hu_mo[ii] = hu_moments_opt(images[ii])\n",
    "    return hu_mo * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_moments = moments_from(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_moments = moments_from(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "km = DummyClassifier().fit(train_moments, train_labels) # 56%\n",
    "km.score(test_moments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "km = make_pipeline(StandardScaler(), LinearSVC(max_iter=1500)).fit(train_moments, train_labels) # 29%\n",
    "km.score(test_moments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "km = KNeighborsClassifier(n_neighbors=6).fit(train_moments, train_labels) # 46%\n",
    "km.score(test_moments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "km = make_pipeline(StandardScaler(), SVC()).fit(train_moments, train_labels) # 87%\n",
    "km.score(test_moments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "km = RandomForestClassifier().fit(train_moments, train_labels) # 100%\n",
    "km.score(test_moments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(km.predict_proba(test_moments)[2])\n",
    "print(km.classes_)\n",
    "print(km.predict(test_moments)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Fusion\n",
    "\n",
    "### Color histogram & Hu moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_early = [np.concatenate((train_histograms[i], train_moments[i])) for i in range(len(train_moments))]\n",
    "test_early = [np.concatenate((test_histograms[i], test_moments[i])) for i in range(len(test_moments))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "early_classifier = DummyClassifier().fit(train_early, train_labels)\n",
    "early_classifier.score(test_early, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "early_classifier = KNeighborsClassifier(n_neighbors=4).fit(train_early, train_labels)\n",
    "early_classifier.score(test_early, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "early_classifier = make_pipeline(StandardScaler(), SVC()).fit(train_early, train_labels)\n",
    "early_classifier.score(test_early, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "early_classifier = make_pipeline(StandardScaler(), LinearSVC(max_iter=1500)).fit(train_early, train_labels)\n",
    "early_classifier.score(test_early, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "early_classifier = RandomForestClassifier().fit(train_early, train_labels)\n",
    "early_classifier.score(test_early, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Fusion\n",
    "\n",
    "### Color histogram & Hu moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "col_classifier = KNeighborsClassifier(n_neighbors=5).fit(train_histograms, train_labels)\n",
    "hu_classifier = RandomForestClassifier().fit(train_moments, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_results = col_classifier.predict_proba(test_histograms), col_classifier.classes_\n",
    "hu_results = hu_classifier.predict_proba(test_moments), hu_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = col_results[0] + hu_results[0], col_results[1]\n",
    "\n",
    "final = np.empty(len(results[0]), dtype='object')\n",
    "for ii in range(results[0].shape[0]):\n",
    "    imax = results[0][ii]\n",
    "    final[ii] = col_results[1][imax.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier save for test program\n",
    "import joblib \n",
    "\n",
    "joblib.dump(col_classifier, \"col.clf\")\n",
    "joblib.dump(hu_classifier, \"hu.clf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
